{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "House Prices: Advanced Regression Techniques - Submissions",
      "provenance": [],
      "collapsed_sections": [
        "rrTbihzkv0b8",
        "xUOoRUeCwX0u",
        "9rZeJQEC0zjd",
        "KTe_Oj_QTE_S",
        "ku7FHam8AG5p",
        "i0DZ-6FdDgCv",
        "5nj0PMFZotXz",
        "-Lv1wImW2YcY",
        "pW_CFhHz3gZ1",
        "0k4PGRemAdK7",
        "1OmrH0jkTb6E",
        "Qwo86irY6lu_",
        "HoltiVPydEgz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anonyms/Kaggle_HousePricesAdvancedRegressionTechniques/blob/master/Blended_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrTbihzkv0b8",
        "colab_type": "text"
      },
      "source": [
        "# Initial Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4IdcjA-v28w",
        "colab_type": "text"
      },
      "source": [
        "Preparing folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvCRz8O8vM0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "housing_data_loctaion = \"~/data/housing/\"\n",
        "submission_file_name = \"submissions.csv\"\n",
        "submission_file_location = housing_data_loctaion + submission_file_name\n",
        "plots_location = \"~/plots/\"\n",
        "!mkdir ~/data\n",
        "!mkdir ~/plots"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYE6RloXv7NF",
        "colab_type": "text"
      },
      "source": [
        "Install/Update OS packages (CAN SKIP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X-dxkKi2VXL",
        "colab_type": "code",
        "outputId": "988c48e8-6250-40ce-ddf7-91c28ef6de38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!apt-get install graphviz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyAh8PATwDA3",
        "colab_type": "text"
      },
      "source": [
        "Install/Update Python packages (CAN SKIP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7l_WWr8sLlX",
        "colab_type": "code",
        "outputId": "6b0d2cfd-8b7d-4d2a-dcf8-fa0bbe2a1f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install unittest2\n",
        "!pip install graphviz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
            "Collecting unittest2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/20/7f0f433060a962200b7272b8c12ba90ef5b903e218174301d0abfd523813/unittest2-1.1.0-py2.py3-none-any.whl (96kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.4 in /usr/local/lib/python3.6/dist-packages (from unittest2) (1.12.0)\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Collecting traceback2\n",
            "  Downloading https://files.pythonhosted.org/packages/17/0a/6ac05a3723017a967193456a2efa0aa9ac4b51456891af1e2353bb9de21e/traceback2-1.4.0-py2.py3-none-any.whl\n",
            "Collecting linecache2\n",
            "  Downloading https://files.pythonhosted.org/packages/c7/a3/c5da2a44c85bfbb6eebcfc1dde24933f8704441b98fdde6528f4831757a6/linecache2-1.0.0-py2.py3-none-any.whl\n",
            "Installing collected packages: argparse, linecache2, traceback2, unittest2\n",
            "Successfully installed argparse-1.4.0 linecache2-1.0.0 traceback2-1.4.0 unittest2-1.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUOoRUeCwX0u",
        "colab_type": "text"
      },
      "source": [
        "# Kaggle Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JBy_wkkwQEo",
        "colab_type": "code",
        "outputId": "ee7b668a-4ed7-4085-d5f7-b31f2189c15a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "##CAN SKIP\n",
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVilrWTAw3ew",
        "colab_type": "code",
        "outputId": "a2764e2a-3fd3-4fb0-b638-7770c7208317",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d6e4f379-4fcd-40f4-bcb1-be0eb090cca0\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d6e4f379-4fcd-40f4-bcb1-be0eb090cca0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"anoynms\",\"key\":\"4b2c6afaefabfef48178035ff45d414b\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITQkuAbzw-EB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV59EB-5xHSu",
        "colab_type": "code",
        "outputId": "77237fef-dd9c-4c02-b67b-77e39a6f5867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!kaggle competitions download -c house-prices-advanced-regression-techniques -p $housing_data_loctaion"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading data_description.txt to /root/data/housing\n",
            "  0% 0.00/13.1k [00:00<?, ?B/s]\n",
            "100% 13.1k/13.1k [00:00<00:00, 11.0MB/s]\n",
            "Downloading test.csv to /root/data/housing\n",
            "  0% 0.00/441k [00:00<?, ?B/s]\n",
            "100% 441k/441k [00:00<00:00, 62.2MB/s]\n",
            "Downloading sample_submission.csv to /root/data/housing\n",
            "  0% 0.00/31.2k [00:00<?, ?B/s]\n",
            "100% 31.2k/31.2k [00:00<00:00, 32.1MB/s]\n",
            "Downloading train.csv to /root/data/housing\n",
            "  0% 0.00/450k [00:00<?, ?B/s]\n",
            "100% 450k/450k [00:00<00:00, 64.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dgSabpLyydI",
        "colab_type": "text"
      },
      "source": [
        "# Read Data into memory & Inits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6crd_WDR03k2",
        "colab_type": "text"
      },
      "source": [
        "Check that the necessary files are there, if note do set-up above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnp5pylyxPLV",
        "colab_type": "code",
        "outputId": "2c5c6d20-9ae3-4b6e-c4fd-41a8577fa0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!ls -l $housing_data_loctaion"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 944\n",
            "-rw-r--r-- 1 root root  13370 Dec 17 17:35 data_description.txt\n",
            "-rw-r--r-- 1 root root  31939 Dec 17 17:35 sample_submission.csv\n",
            "-rw-r--r-- 1 root root 451405 Dec 17 17:35 test.csv\n",
            "-rw-r--r-- 1 root root 460676 Dec 17 17:35 train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Env4cY47wKqG",
        "colab_type": "text"
      },
      "source": [
        "Imports and inits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRHpQzGMwJhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from pandas.util.testing import assert_series_equal\n",
        "import unittest\n",
        "from mpl_toolkits import mplot3d\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from scipy.stats import norm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy import stats\n",
        "import time\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "tc = unittest.TestCase('__init__')\n",
        "tc.maxDiff = None\n",
        "seed = 666"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeZM7VVCy4D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaTe1qBR1Crq",
        "colab_type": "text"
      },
      "source": [
        "Evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkgG0WBJ09e6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_predictions(actual, predicted):\n",
        "    mse = mean_squared_error(actual, predicted)\n",
        "    rmse = np.sqrt(mse)\n",
        "    return(rmse)\n",
        "def eval_predictions_mean(actual, predicted):\n",
        "    rel_error = []\n",
        "    for i in actual:\n",
        "      diff = abs(actual-predicted)/actual\n",
        "      rel_error.append(diff)\n",
        "    rel_error_arry = np.array(rel_error)\n",
        "    return(rel_error_arry.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rZeJQEC0zjd",
        "colab_type": "text"
      },
      "source": [
        "# Coding Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k3T6x0c3iAJ",
        "colab_type": "text"
      },
      "source": [
        "Pick labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRph0ZwB3hL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearBuilt',\n",
        "            '1stFlrSF', '2ndFlrSF',\n",
        "            'FullBath','YearRemodAdd'] ## CHANGE ME TO TRY DIFFERENT FEATURES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT9LVk5V1Edo",
        "colab_type": "text"
      },
      "source": [
        "Picking method & training it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUmYcHC91Ayv",
        "colab_type": "code",
        "outputId": "33aab95d-6773-4def-fe54-ef1a120c89e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)\n",
        "\n",
        "# Define model\n",
        "my_model = DecisionTreeRegressor(max_depth=3, min_samples_leaf=5) \n",
        "\n",
        "# Fit model\n",
        "my_model.fit(train_X, train_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
              "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=5,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      presort=False, random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlCXLTAP30BK",
        "colab_type": "text"
      },
      "source": [
        "Evalute model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxkTXCbBS_lZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_R3RbsD3zrE",
        "colab_type": "code",
        "outputId": "e13cace6-b8aa-4a6f-b90b-cb430687c13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "val_predictions = my_model.predict(val_X)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5d0b90463deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_predictions_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eval_predictions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d4gHVPeS64e",
        "colab_type": "text"
      },
      "source": [
        "My own attempts\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KTe_Oj_QTE_S"
      },
      "source": [
        "# Coding My Own Solution - 1st attempt - More Advanced Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzGD0j6iTSca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agogC1qlTr-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VejnfakiTWsW",
        "colab_type": "code",
        "outputId": "3b9af250-42f0-45ab-deb0-c30f83febdc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)\n",
        "\n",
        "# Define model\n",
        "my_model = DecisionTreeRegressor(max_depth=5, min_samples_leaf=5) \n",
        "\n",
        "# Fit model\n",
        "my_model.fit(train_X, train_y)\n",
        "\n",
        "val_predictions = my_model.predict(val_X)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36990.78414692297\n",
            "0.1591561750136834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl3IW7dE4j5j",
        "colab_type": "code",
        "outputId": "883533a6-97b7-4fce-b39a-22e1cb18ae64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "competition_unseen_data_no_labels[competition_unseen_data_no_labels[features].isna().any(axis=1)][features]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-af09cf6f758c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompetition_unseen_data_no_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompetition_unseen_data_no_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Neighborhood_Somerst', 'Neighborhood_Crawfor', 'YearsBetween', 'Neighborhood_ClearCr', 'Neighborhood_StoneBr', 'Neighborhood_OldTown', 'Neighborhood_Veenker', 'Neighborhood_Edwards', 'Neighborhood_MeadowV', 'Neighborhood_Mitchel', 'Neighborhood_SawyerW', 'Neighborhood_SWISU', 'Neighborhood_NWAmes', 'Neighborhood_Blueste', 'Neighborhood_NridgHt', 'Neighborhood_Blmngtn', 'Neighborhood_NPkVill', 'Neighborhood_NAmes', 'Neighborhood_CollgCr', 'Neighborhood_Gilbert', 'Neighborhood_IDOTRR', 'Neighborhood_NoRidge', 'Neighborhood_Sawyer', 'Neighborhood_BrDale', 'Neighborhood_BrkSide', 'Neighborhood_Timber'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vtHFhIl1TpD",
        "colab_type": "text"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ku7FHam8AG5p"
      },
      "source": [
        "# Coding My Own Solution - 2nd attempt - Random Forrest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wHRsn8HgAG5r",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QO3U7kPxAG5u",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8efe1d36-8dc1-4e7d-81dc-8325ce7f0f57",
        "id": "bXGiqFgaAG5w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)\n",
        "\n",
        "# Define model\n",
        "my_model = RandomForestRegressor(n_estimators = 100, max_depth=5, min_samples_leaf=5) \n",
        "\n",
        "# Fit model\n",
        "my_model.fit(train_X, train_y)\n",
        "\n",
        "val_predictions = my_model.predict(val_X)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35299.93140963212\n",
            "0.13487767384237473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jcHOl2TSAG5z"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siCcyXOp1R-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "# Predict\n",
        "predictions = my_model.predict(competition_unseen_data_no_labels[features])\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i0DZ-6FdDgCv"
      },
      "source": [
        "# Coding My Own Solution - 3rd attempt - MPL 1st attempt\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pKsT04SyDgCx",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0021CJSrDgC0",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cnN_SqEUDgC2",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbsTEpu71PyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = RobustScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bazCR8pu1P5z",
        "colab_type": "code",
        "outputId": "11199665-2d40-45d3-a394-52a86ed55983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Define model\n",
        "my_model = MLPRegressor(hidden_layer_sizes=(30,20,20),  activation='relu', solver='adam', alpha=0.001, batch_size='auto',\n",
        "    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
        "    random_state=21, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
        "    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08) \n",
        "\n",
        "# Fit model\n",
        "my_model.fit(scaled_train_X_df, train_y)\n",
        "\n",
        "val_predictions = my_model.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28816.86952584894\n",
            "0.10675970071656819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f3NahuOKDgC4"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "70GRgULCDgC4",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Predict\n",
        "predictions = my_model.predict(scaler.transform(competition_unseen_data_no_labels[features]))\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8CD7Jja5DgC6"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bbfa46bc-cd4a-46a7-9c56-eaef78e02573",
        "id": "hber8piwDgC6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "submission_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>133218.283056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>153918.543292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>164379.437372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>186671.829623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>260588.297393</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Id      SalePrice\n",
              "0  1461  133218.283056\n",
              "1  1462  153918.543292\n",
              "2  1463  164379.437372\n",
              "3  1464  186671.829623\n",
              "4  1465  260588.297393"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5nj0PMFZotXz"
      },
      "source": [
        "# Coding My Own Solution - 4th attempt - GridSearch on MPL\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YK-s2rDuotX1",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b4dJlcdtotX4",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkVXe1oeNQx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b83ieIYbNWSc",
        "colab_type": "code",
        "outputId": "804831f3-1c26-4781-f075-5bfa1af982c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "train_X.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearsBetween</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>Neighborhood_Blmngtn</th>\n",
              "      <th>Neighborhood_Blueste</th>\n",
              "      <th>Neighborhood_BrDale</th>\n",
              "      <th>Neighborhood_BrkSide</th>\n",
              "      <th>Neighborhood_ClearCr</th>\n",
              "      <th>Neighborhood_CollgCr</th>\n",
              "      <th>Neighborhood_Crawfor</th>\n",
              "      <th>Neighborhood_Edwards</th>\n",
              "      <th>Neighborhood_Gilbert</th>\n",
              "      <th>Neighborhood_IDOTRR</th>\n",
              "      <th>Neighborhood_MeadowV</th>\n",
              "      <th>Neighborhood_Mitchel</th>\n",
              "      <th>Neighborhood_NAmes</th>\n",
              "      <th>Neighborhood_NPkVill</th>\n",
              "      <th>Neighborhood_NWAmes</th>\n",
              "      <th>Neighborhood_NoRidge</th>\n",
              "      <th>Neighborhood_NridgHt</th>\n",
              "      <th>Neighborhood_OldTown</th>\n",
              "      <th>Neighborhood_SWISU</th>\n",
              "      <th>Neighborhood_Sawyer</th>\n",
              "      <th>Neighborhood_SawyerW</th>\n",
              "      <th>Neighborhood_Somerst</th>\n",
              "      <th>Neighborhood_StoneBr</th>\n",
              "      <th>Neighborhood_Timber</th>\n",
              "      <th>Neighborhood_Veenker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>6</td>\n",
              "      <td>32</td>\n",
              "      <td>6</td>\n",
              "      <td>2073</td>\n",
              "      <td>0</td>\n",
              "      <td>13175</td>\n",
              "      <td>1542</td>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>1988</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>6</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "      <td>1236</td>\n",
              "      <td>0</td>\n",
              "      <td>10011</td>\n",
              "      <td>1070</td>\n",
              "      <td>447</td>\n",
              "      <td>1</td>\n",
              "      <td>1996</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>4676</td>\n",
              "      <td>1538</td>\n",
              "      <td>40094</td>\n",
              "      <td>3138</td>\n",
              "      <td>884</td>\n",
              "      <td>3</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1108</th>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1690</td>\n",
              "      <td>742</td>\n",
              "      <td>8063</td>\n",
              "      <td>924</td>\n",
              "      <td>463</td>\n",
              "      <td>2</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>6</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>1232</td>\n",
              "      <td>0</td>\n",
              "      <td>11120</td>\n",
              "      <td>1232</td>\n",
              "      <td>516</td>\n",
              "      <td>2</td>\n",
              "      <td>1984</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      OverallCond  YearsBetween  ...  Neighborhood_Timber  Neighborhood_Veenker\n",
              "1456            6            32  ...                    0                     0\n",
              "215             6            49  ...                    0                     0\n",
              "523             5             0  ...                    0                     0\n",
              "1108            5             7  ...                    0                     0\n",
              "160             6            24  ...                    0                     1\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RVf5YJTpotX5",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = RobustScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCqS1CLPPNDv",
        "colab_type": "code",
        "outputId": "15d3fefc-149f-46f3-8571-670273434b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "scaled_train_X_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearsBetween</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>Neighborhood_Blmngtn</th>\n",
              "      <th>Neighborhood_Blueste</th>\n",
              "      <th>Neighborhood_BrDale</th>\n",
              "      <th>Neighborhood_BrkSide</th>\n",
              "      <th>Neighborhood_ClearCr</th>\n",
              "      <th>Neighborhood_CollgCr</th>\n",
              "      <th>Neighborhood_Crawfor</th>\n",
              "      <th>Neighborhood_Edwards</th>\n",
              "      <th>Neighborhood_Gilbert</th>\n",
              "      <th>Neighborhood_IDOTRR</th>\n",
              "      <th>Neighborhood_MeadowV</th>\n",
              "      <th>Neighborhood_Mitchel</th>\n",
              "      <th>Neighborhood_NAmes</th>\n",
              "      <th>Neighborhood_NPkVill</th>\n",
              "      <th>Neighborhood_NWAmes</th>\n",
              "      <th>Neighborhood_NoRidge</th>\n",
              "      <th>Neighborhood_NridgHt</th>\n",
              "      <th>Neighborhood_OldTown</th>\n",
              "      <th>Neighborhood_SWISU</th>\n",
              "      <th>Neighborhood_Sawyer</th>\n",
              "      <th>Neighborhood_SawyerW</th>\n",
              "      <th>Neighborhood_Somerst</th>\n",
              "      <th>Neighborhood_StoneBr</th>\n",
              "      <th>Neighborhood_Timber</th>\n",
              "      <th>Neighborhood_Veenker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.063830</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.961059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.885600</td>\n",
              "      <td>1.123849</td>\n",
              "      <td>0.079523</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.131579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.297872</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-0.342679</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.117918</td>\n",
              "      <td>0.157625</td>\n",
              "      <td>-0.131213</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.744681</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.015576</td>\n",
              "      <td>2.112637</td>\n",
              "      <td>7.416960</td>\n",
              "      <td>4.390993</td>\n",
              "      <td>1.606362</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.394737</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1108</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.595745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.364486</td>\n",
              "      <td>1.019231</td>\n",
              "      <td>-0.354725</td>\n",
              "      <td>-0.141249</td>\n",
              "      <td>-0.067594</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.234043</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.348910</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.386995</td>\n",
              "      <td>0.489253</td>\n",
              "      <td>0.143141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.236842</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      OverallCond  YearsBetween  ...  Neighborhood_Timber  Neighborhood_Veenker\n",
              "1456          1.0     -0.063830  ...                  0.0                   0.0\n",
              "215           1.0      0.297872  ...                  0.0                   0.0\n",
              "523           0.0     -0.744681  ...                  0.0                   0.0\n",
              "1108          0.0     -0.595745  ...                  0.0                   0.0\n",
              "160           1.0     -0.234043  ...                  0.0                   1.0\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0-j5JaptZa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gsc = GridSearchCV(\n",
        "    estimator=MLPRegressor(),\n",
        "    param_grid = {\n",
        "        'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
        "        'hidden_layer_sizes': [(30,20,20), (60,40,20), (100,80,60)],\n",
        "        'alpha': [0.001,0.01,0.0001],\n",
        "        'activation': [\"logistic\", \"relu\", \"tanh\"]\n",
        "     },cv=5, verbose=1,n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbejQsfGNTGQ",
        "colab_type": "code",
        "outputId": "a000f91a-ecd6-4f65-d9a2-aa8dbcd76ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Define model\n",
        "##my_model = MLPRegressor(hidden_layer_sizes=(30,20,20),  activation='relu', solver='adam', alpha=0.001, batch_size='auto',\n",
        "##    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
        "##    random_state=21, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
        "##    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08) \n",
        "\n",
        "# Fit model\n",
        "gsc.fit(scaled_train_X_df, train_y)\n",
        "\n",
        "val_predictions = gsc.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  8.6min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32831.06771111576\n",
            "0.1392507540707426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RmD4Hzg-otX8"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mn9HfKTSotX9",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Predict\n",
        "predictions = gsc.predict(scaler.transform(competition_unseen_data_no_labels[features]))\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-7PhCx38otX_"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Lv1wImW2YcY"
      },
      "source": [
        "# Coding My Own Solution - 5th attempt - Linear Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_71FnMzq2Ycc",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1PbsCoFU2Yce",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T8Y_hXoW2Ycg",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h00u0EQ92Yck",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = RobustScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5d37c871-3e79-4652-91c3-c2daa94d639f",
        "id": "Y124bOpi2Yco",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "my_model = LinearRegression()\n",
        "\n",
        "# Fit model\n",
        "my_model.fit(scaled_train_X_df, train_y)\n",
        "\n",
        "val_predictions = my_model.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32501.627559577162\n",
            "0.11597645351604813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XeG_P0tn2Ycr"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rwmQD8DJ2Ycr",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Predict\n",
        "predictions = my_model.predict(scaler.transform(competition_unseen_data_no_labels[features]))\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JmZK7URh2Yct"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pW_CFhHz3gZ1"
      },
      "source": [
        "# Coding My Own Solution - 6th attempt - SVM Regressor w GridSearch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wINFr-Op3gZ4",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C26A2V1u3gZ6",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c50Vhs2u3gZ8",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JlgoimlY3gZ9",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = RobustScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eDYZdAFP3gZ_",
        "colab": {}
      },
      "source": [
        "svr = GridSearchCV(SVR(), cv=5,\n",
        "                   param_grid={\"C\": [1e0],\n",
        "                               \"gamma\": np.logspace(-2, 2, 5),\n",
        "                               \"kernel\":['rbf','poly','sigmoid']},verbose=2)\n",
        "\n",
        "# Fit model\n",
        "svr.fit(scaled_train_X_df, train_y)\n",
        "\n",
        "val_predictions = svr.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AOVbqHEz3gaA"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-EZiTmuD3gaB",
        "outputId": "556c4835-a3af-4a79-cffb-ec90b267f8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Predict\n",
        "predictions = svr.predict(scaler.transform(competition_unseen_data_no_labels[features]))\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-88e5ce51b453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompetition_unseen_data_no_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompetition_unseen_data_no_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcompetition_unseen_data_no_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'YearsBetween'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompetition_unseen_data_no_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'YrSold'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcompetition_unseen_data_no_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'YearBuilt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcompetition_unseen_data_no_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GarageArea'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcompetition_unseen_data_no_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotalBsmtSF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "au_JkWXc3gaC"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0k4PGRemAdK7"
      },
      "source": [
        "# Coding My Own Solution - 7th attempt - MPL with my own GridSearch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VBPKkVuUAdK-",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-AxGkQJfAdLB",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PWT7ZfO6AdLC",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bMjR1fEkAdLE",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = RobustScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f1dd987d-095e-460e-daa1-d1494df16968",
        "id": "nkNx-wh9AdLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Define model\n",
        "layers = [(40,20,10),(50,30,30),(70,50,20)]\n",
        "activations = ['relu','tanh']\n",
        "solvers = ['adam','sgd']\n",
        "learning_rate_inits = [0.001,0.0001]\n",
        "max_iterations = [1000,2000,5000]\n",
        "best_eval = 0.8\n",
        "best_params =[-1,\"\",\"\",-1,-1]\n",
        "start_time = time.time()\n",
        "i = 0\n",
        "start_time1 = time.time()\n",
        "for l in layers:\n",
        "  for a in activations:\n",
        "    for s in solvers:\n",
        "      for lri in learning_rate_inits:\n",
        "        for m in max_iterations:\n",
        "          i = i+1\n",
        "          print(\"Attempt : \",i)\n",
        "          lapsed_time = time.time() - start_time\n",
        "          print(lapsed_time)\n",
        "          start_time = time.time()\n",
        "          my_model = MLPRegressor(hidden_layer_sizes=l,  activation=a, solver=s, alpha=0.001, batch_size='auto',\n",
        "              learning_rate='constant', learning_rate_init=lri, power_t=0.5, max_iter=m, shuffle=True,\n",
        "              random_state=21, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
        "              early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08) \n",
        "          my_model.fit(scaled_train_X_df, train_y)\n",
        "          val_predictions = my_model.predict(scaled_val_X_df)\n",
        "          my_eval = eval_predictions_mean(val_y, val_predictions)\n",
        "          if my_eval < best_eval:\n",
        "            best_eval = my_eval\n",
        "            best_params = [l,a,s,lri,m]\n",
        "lapsed_time1 = time.time() - start_time1\n",
        "print(\"Total time : \",lapsed_time1)\n",
        "print(best_eval)\n",
        "print(best_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attempt :  1\n",
            "0.0008671283721923828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  2\n",
            "7.568844795227051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  3\n",
            "14.959973096847534\n",
            "Attempt :  4\n",
            "26.231079816818237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  5\n",
            "7.736956357955933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  6\n",
            "15.052759170532227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  7\n",
            "37.88541126251221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  8\n",
            "6.94603967666626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  9\n",
            "13.7027108669281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  10\n",
            "34.008610248565674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  11\n",
            "6.824429512023926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  12\n",
            "13.509276390075684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  13\n",
            "33.5665922164917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  14\n",
            "10.384809494018555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  15\n",
            "20.61455249786377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  16\n",
            "50.876548528671265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  17\n",
            "10.308078289031982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  18\n",
            "20.556854248046875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  19\n",
            "50.8612265586853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  20\n",
            "6.331218004226685\n",
            "Attempt :  21\n",
            "6.665630102157593\n",
            "Attempt :  22\n",
            "6.68215274810791\n",
            "Attempt :  23\n",
            "1.2221615314483643\n",
            "Attempt :  24\n",
            "1.2166805267333984\n",
            "Attempt :  25\n",
            "1.2211105823516846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  26\n",
            "8.92458176612854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  27\n",
            "17.662569046020508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  28\n",
            "49.09096717834473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  29\n",
            "9.138244152069092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  30\n",
            "17.847165822982788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  31\n",
            "47.22028350830078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  32\n",
            "7.562356233596802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  33\n",
            "14.951163291931152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  34\n",
            "36.658581256866455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  35\n",
            "8.292680263519287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  36\n",
            "16.347404718399048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  37\n",
            "40.60566020011902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  38\n",
            "13.888041973114014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  39\n",
            "27.612609386444092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  40\n",
            "68.92243957519531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  41\n",
            "13.876945734024048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  42\n",
            "27.532261848449707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  43\n",
            "68.52474021911621\n",
            "Attempt :  44\n",
            "0.577216625213623\n",
            "Attempt :  45\n",
            "0.5791985988616943\n",
            "Attempt :  46\n",
            "0.581648588180542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  47\n",
            "8.325356721878052\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  48\n",
            "16.387208461761475\n",
            "Attempt :  49\n",
            "21.072782516479492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  50\n",
            "10.612348556518555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  51\n",
            "21.100789308547974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  52\n",
            "59.797781229019165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  53\n",
            "10.764580011367798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  54\n",
            "21.06417465209961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  55\n",
            "56.918198108673096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_base.py:195: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  56\n",
            "8.976329803466797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_base.py:195: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  57\n",
            "17.628186225891113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_base.py:195: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  58\n",
            "43.62643623352051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  59\n",
            "10.114683628082275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  60\n",
            "19.983612775802612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  61\n",
            "50.05950975418091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  62\n",
            "17.01624083518982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  63\n",
            "33.96265363693237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  64\n",
            "58.04734754562378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  65\n",
            "1.2090857028961182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attempt :  66\n",
            "1.2365436553955078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIvVnEErBW0z",
        "colab_type": "code",
        "outputId": "f93af383-703c-4e79-ed44-a4d3a06808d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(best_params)\n",
        "print(best_params[0])\n",
        "print(best_params[1])\n",
        "print(best_params[2])\n",
        "print(best_params[3])\n",
        "print(best_params[4])\n",
        "\n",
        "my_model = MLPRegressor(hidden_layer_sizes=best_params[0],  activation=best_params[1], solver=best_params[2], alpha=0.001, batch_size='auto',\n",
        "    learning_rate='constant', learning_rate_init=best_params[3], power_t=0.5, max_iter=best_params[4], shuffle=True,\n",
        "    random_state=21, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
        "    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08) \n",
        "my_model.fit(scaled_train_X_df, train_y)\n",
        "val_predictions = my_model.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(70, 50, 20), 'relu', 'adam', 0.001, 5000]\n",
            "(70, 50, 20)\n",
            "relu\n",
            "adam\n",
            "0.001\n",
            "5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "27165.64476564762\n",
            "0.10287558979641247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w7-0hgLkAdLH"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zsYPZ9v8AdLI",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Predict\n",
        "predictions = my_model.predict(scaler.transform(competition_unseen_data_no_labels[features]))\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VeF_LIIzAdLJ"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d44c9580-3723-4b09-da86-0b5e1424154d",
        "id": "isQbFbqAAdLK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "submission_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>131610.052063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>159502.092981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>179036.584978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>184343.129902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>204477.160743</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Id      SalePrice\n",
              "0  1461  131610.052063\n",
              "1  1462  159502.092981\n",
              "2  1463  179036.584978\n",
              "3  1464  184343.129902\n",
              "4  1465  204477.160743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1OmrH0jkTb6E"
      },
      "source": [
        "# Coding My Own Solution - 8th attempt - Outliers And best MPL\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7jAsTup0Tb6J",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X8_wI7-yTb6M",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0omfkOe8UFea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Remove Outliers\n",
        "train.sort_values(by = 'GrLivArea', ascending = False)[:2]\n",
        "train = train.drop(train[train['Id'] == 1299].index)\n",
        "train = train.drop(train[train['Id'] == 524].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol5B84P-WN4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.sort_values(by = 'LotArea', ascending = False)[:10]\n",
        "train = train.drop(train[train['LotArea']>=115000].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onRsjddjUHBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Logarithm Normalizer\n",
        "##train['SalePrice'] = np.log(train['SalePrice'])\n",
        "##train['GrLivArea'] = np.log(train['GrLivArea'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aNQPGbvATb6O",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nUyp7wCJTb6P",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = RobustScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "33705301-20fb-4b20-d2cf-90a4b5919b4e",
        "id": "RKiJqlFVTb6S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## Best Params from previous attempt\n",
        "best_params = [(70, 50, 20), 'relu', 'adam', 0.001, 5000]\n",
        "\n",
        "my_model = MLPRegressor(hidden_layer_sizes=best_params[0],  activation=best_params[1], solver=best_params[2], alpha=0.001, batch_size='auto',\n",
        "    learning_rate='constant', learning_rate_init=best_params[3], power_t=0.5, max_iter=best_params[4], shuffle=True,\n",
        "    random_state=21, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
        "    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08) \n",
        "my_model.fit(scaled_train_X_df, train_y)\n",
        "val_predictions = my_model.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24877.134260260606\n",
            "0.09762363879412542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Vviz113Tb6U"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QNPhk48ZTb6U",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Predict\n",
        "predictions = my_model.predict(scaler.transform(competition_unseen_data_no_labels[features]))\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4_R5yO13Tb6W"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qwo86irY6lu_"
      },
      "source": [
        "# Coding My Own Solution - 9th attempt - Linear Regression w Outliers removal and PCA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vQph55cy6lvE",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p04ZnXlq6lvH",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTsIewio7VTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Remove Outliers\n",
        "train.sort_values(by = 'GrLivArea', ascending = False)[:2]\n",
        "train = train.drop(train[train['Id'] == 1299].index)\n",
        "train = train.drop(train[train['Id'] == 524].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxDno4Xy7WGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.sort_values(by = 'LotArea', ascending = False)[:10]\n",
        "train = train.drop(train[train['LotArea']>=115000].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dv34DOLj6lvI",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "scaler = RobustScaler()  \n",
        "scaler.fit(X.values)  \n",
        "scaled_X = scaler.transform(X.values)  \n",
        "\n",
        "\n",
        "pca_hp = PCA(30)\n",
        "x_fit = pca_hp.fit_transform(scaled_X)\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(x_fit, y,random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b0940ff4-147f-41af-aabd-63531342b429",
        "id": "wj-I-o6n6lvL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "my_model = LinearRegression()\n",
        "\n",
        "# Fit model\n",
        "my_model.fit(train_X, train_y)\n",
        "\n",
        "val_predictions = my_model.predict(val_X)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29340.2439509192\n",
            "0.12257583375517789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iX2H1B2E6lvN"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekQPhG-z_h7H",
        "colab_type": "code",
        "outputId": "511d29a4-53f0-4ef5-bb17-667c182b1309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "competition_unseen_data_no_labels.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                 int64\n",
              "MSSubClass         int64\n",
              "MSZoning          object\n",
              "LotFrontage      float64\n",
              "LotArea            int64\n",
              "                  ...   \n",
              "MiscVal            int64\n",
              "MoSold             int64\n",
              "YrSold             int64\n",
              "SaleType          object\n",
              "SaleCondition     object\n",
              "Length: 80, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DNYQszZl6lvO",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "competition_X = competition_unseen_data_no_labels[features]\n",
        " \n",
        "scaled_X = scaler.transform(competition_X.values) \n",
        "\n",
        "x_fit = pca_hp.transform(scaled_X)\n",
        "\n",
        "# Predict\n",
        "predictions = my_model.predict(x_fit)\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xdY2-CYj6lvP"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gPetPWcTXQrp"
      },
      "source": [
        "# Coding My Own Solution - 10th attempt - Lasso Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h5do7cYNXQrr",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WQ6moDikXQrt",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7M3B2qvwXQru",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cU0RIbJsXQrx",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "51486789-3bbd-4a91-e438-29c6d2970315",
        "id": "lbiSVBGzXQry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "my_model = Lasso(alpha=0.1)\n",
        "\n",
        "# Fit model\n",
        "my_model.fit(scaled_train_X_df, train_y)\n",
        "\n",
        "val_predictions = my_model.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 87941029599.73376, tolerance: 698417822.4562681\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32501.57536932442\n",
            "0.1159759443923259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CunHINXXXQr0"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f0PZI-EHXQr0",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Predict\n",
        "predictions = my_model.predict(scaler.transform(competition_unseen_data_no_labels[features]))\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tNDlHqwdXQr2"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HoltiVPydEgz"
      },
      "source": [
        "# Coding My Own Solution - 11th attempt - Lasso Regression CV\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qsWI10Y4dEg9",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kWGY5aDrdEhD",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vayTnDqDdEhF",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-btJh0o1dEhI",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d00e4313-9745-442f-d1f0-315134984b28",
        "id": "a5LNQVejdEhK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "my_model = LassoCV()\n",
        "\n",
        "# Fit model\n",
        "my_model.fit(scaled_train_X_df, train_y)\n",
        "\n",
        "val_predictions = my_model.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32387.24773458353\n",
            "0.11442374804793436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b6XjU8bSdEhN"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cI9OwmCNdEhO",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Predict\n",
        "predictions = my_model.predict(scaler.transform(competition_unseen_data_no_labels[features]))\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q4VgOHNNdEhP"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gbI6JTHYagGS"
      },
      "source": [
        "# Coding My Own Solution - 12th attempt - Ridge Regression CV\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0kqLeuimagGb",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HjqjV9FBagGj",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Z2C3wL8agGm",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uViPFmYXagGp",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = MinMaxScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "47979ef2-ad67-4c03-844d-fed230225238",
        "id": "Fd6o3QFgagGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "my_model = RidgeCV()\n",
        "\n",
        "# Fit model\n",
        "my_model.fit(scaled_train_X_df, train_y)\n",
        "\n",
        "val_predictions = my_model.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32808.06311984203\n",
            "0.11572049423364916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JKQCmkC6agGw"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PWwXK98AagGw",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Predict\n",
        "predictions = my_model.predict(scaler.transform(competition_unseen_data_no_labels[features]))\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cp54UbceagGz"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5lFhEwKel5k"
      },
      "source": [
        "# Coding My Own Solution - 13th attempt - Gradient Boost Regressions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ltFbgoKqel5m",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LxlYYoyXel5o",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)\n",
        "train['GarageArea'].fillna(0, inplace=True)\n",
        "train['TotalBsmtSF'].fillna(0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qVJ65IPZel5p",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQCOBkqQel5r",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = MinMaxScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c45fbeef-fbb4-4fc5-8fbe-6fe4dd447d06",
        "id": "fd_82ERDel5s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "my_model = GradientBoostingRegressor(max_depth = 4)\n",
        "\n",
        "# Fit model\n",
        "my_model.fit(scaled_train_X_df, train_y)\n",
        "\n",
        "val_predictions = my_model.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27652.984584153703\n",
            "0.10518006558344765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3CgEb_1pel5t"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xpF06Flgel5u",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Predict\n",
        "predictions = my_model.predict(scaler.transform(competition_unseen_data_no_labels[features]))\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8l-jTHW4el5w"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zR52_9Al6o0i"
      },
      "source": [
        "# Coding My Own Solution - 15th attempt - XG Boost Regressor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jcegKEs6gr2q",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1cfSZrD1gr2t",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)\n",
        "train['GarageArea'].fillna(0, inplace=True)\n",
        "train['TotalBsmtSF'].fillna(0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jwA8IBUHgr2u",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jIfeQuEi1Sb",
        "colab_type": "code",
        "outputId": "199f8400-762a-45e0-d886-eaca1d8472c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.17.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwTw5Rw5i4mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from xgboost import XGBRegressor\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Z-yUIdjgr2v",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = MinMaxScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "464bb53e-78d3-402c-cec9-9532e723e9ff",
        "id": "VvYJc-aAgr2w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "my_model = XGBRegressor(max_depth = 5, learning_rate = 0.15)\n",
        "\n",
        "# Fit model\n",
        "my_model.fit(scaled_train_X_df, train_y)\n",
        "\n",
        "val_predictions = my_model.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:46:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "29905.11105826259\n",
            "0.10651820739205436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V_mUQuz7gr2y"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rws_rj1Ogr2y",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "competition_unseen_data_no_labels_features = competition_unseen_data_no_labels[features]\n",
        "scaled_competition_unseen_data_no_labels = scaler.transform(competition_unseen_data_no_labels_features.values)\n",
        "scaled_competition_unseen_data_no_labels_df = pd.DataFrame(scaled_competition_unseen_data_no_labels,index=competition_unseen_data_no_labels_features.index,columns=competition_unseen_data_no_labels_features.columns) \n",
        "# Predict\n",
        "predictions = my_model.predict(scaled_competition_unseen_data_no_labels_df)\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "47XUdxRrgr2z"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N0OZcl0u66rG"
      },
      "source": [
        "# Coding My Own Solution - 16th attempt - Light GBM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jckgyfRp66rR",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor\n",
        "from lightgbm import LGBMClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XUuSfaCQ66rJ",
        "colab": {}
      },
      "source": [
        "label_name = 'SalePrice'\n",
        "features = ['OverallCond', 'YearsBetween','OverallQual',\n",
        "            'GrLivArea', '2ndFlrSF','LotArea','TotalBsmtSF','GarageArea',\n",
        "            'FullBath','YearRemodAdd','Neighborhood_Blmngtn','Neighborhood_Blueste','Neighborhood_BrDale','Neighborhood_BrkSide', 'Neighborhood_ClearCr',\n",
        "            'Neighborhood_CollgCr','Neighborhood_Crawfor','Neighborhood_Edwards','Neighborhood_Gilbert','Neighborhood_IDOTRR','Neighborhood_MeadowV',\n",
        "            'Neighborhood_Mitchel','Neighborhood_NAmes','Neighborhood_NPkVill','Neighborhood_NWAmes','Neighborhood_NoRidge','Neighborhood_NridgHt','Neighborhood_OldTown',\n",
        "            'Neighborhood_SWISU','Neighborhood_Sawyer','Neighborhood_SawyerW','Neighborhood_Somerst','Neighborhood_StoneBr','Neighborhood_Timber','Neighborhood_Veenker']\n",
        "train = pd.read_csv(housing_data_loctaion + \"train.csv\")\n",
        "data = train.copy()\n",
        "test = pd.read_csv(housing_data_loctaion + \"test.csv\")\n",
        "newdata = test.copy()\n",
        "competition_unseen_data_no_labels = test.copy()\n",
        "output_sample = pd.read_csv(housing_data_loctaion + \"sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YwRZLzfJ66rL",
        "colab": {}
      },
      "source": [
        "train['YearsBetween'] = train['YrSold']-train['YearBuilt']\n",
        "train = pd.get_dummies(train)\n",
        "train['GarageArea'].fillna(0, inplace=True)\n",
        "train['TotalBsmtSF'].fillna(0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_fUTklbN66rN",
        "colab": {}
      },
      "source": [
        "# Assign \"Mathy\" names to look like a data scientist\n",
        "# The label is a small y because its a vector (only 1 column)\n",
        "y = train[label_name]\n",
        "# The features are a big X because its a feature matrix (n rows, m feature columns)\n",
        "X = train[features]\n",
        "\n",
        "# Split to train and test\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pIN5vxF166rS",
        "colab": {}
      },
      "source": [
        "# Scaling all parameters\n",
        "scaler = MinMaxScaler()  \n",
        "scaler.fit(train_X.values)  \n",
        "scaled_train_X = scaler.transform(train_X.values)  \n",
        "scaled_val_X = scaler.transform(val_X.values)\n",
        "\n",
        "scaled_train_X_df = pd.DataFrame(scaled_train_X,index=train_X.index,columns=train_X.columns)\n",
        "scaled_val_X_df = pd.DataFrame(scaled_val_X,index=val_X.index,columns=val_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "477c725e-f559-4b00-96b6-2295c45e156e",
        "id": "oNy_1Dyo66rU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Fit model\n",
        "lgb_dataset = lgb.Dataset(scaled_train_X_df, label=train_y)\n",
        "params = {}\n",
        "params['learning_rate'] = 0.003\n",
        "params['boosting_type'] = 'gbdt'\n",
        "params['objective'] = 'binary'\n",
        "params['metric'] = 'binary_logloss'\n",
        "params['sub_feature'] = 0.5\n",
        "params['num_leaves'] = 10\n",
        "params['min_data'] = 50\n",
        "params['max_depth'] = 10\n",
        "clf = lgb.train(params, lgb_dataset, 100)\n",
        "\n",
        "val_predictions=clf.predict(scaled_val_X_df)\n",
        "\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "197466.92757334022\n",
            "0.9999935759783006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiaFF-x-XdmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44386c4b-193f-40e8-b323-269869056416"
      },
      "source": [
        "my_model = LGBMRegressor(objective='regression', \n",
        "                                       num_leaves=4,\n",
        "                                       learning_rate=0.01, \n",
        "                                       n_estimators=5000,\n",
        "                                       max_bin=200, \n",
        "                                       bagging_fraction=0.75,\n",
        "                                       bagging_freq=5, \n",
        "                                       bagging_seed=7,\n",
        "                                       feature_fraction=0.2,\n",
        "                                       feature_fraction_seed=7,\n",
        "                                       verbose=-1,\n",
        "                                       )\n",
        "\n",
        "# Fit model\n",
        "my_model.fit(scaled_train_X_df, train_y)\n",
        "\n",
        "val_predictions = my_model.predict(scaled_val_X_df)\n",
        "print(eval_predictions(val_y, val_predictions))\n",
        "print(eval_predictions_mean(val_y, val_predictions))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29652.77866082081\n",
            "0.10448041114206295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o9WrhV-366rV"
      },
      "source": [
        "Predict new data using model & Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j0c_XRxS66rW",
        "colab": {}
      },
      "source": [
        "competition_unseen_data_no_labels = pd.get_dummies(competition_unseen_data_no_labels)\n",
        "competition_unseen_data_no_labels['YearsBetween'] = competition_unseen_data_no_labels['YrSold']-competition_unseen_data_no_labels['YearBuilt']\n",
        "competition_unseen_data_no_labels['GarageArea'].fillna(0, inplace=True)\n",
        "competition_unseen_data_no_labels['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "\n",
        "competition_unseen_data_no_labels_features = competition_unseen_data_no_labels[features]\n",
        "scaled_competition_unseen_data_no_labels = scaler.transform(competition_unseen_data_no_labels_features.values)\n",
        "scaled_competition_unseen_data_no_labels_df = pd.DataFrame(scaled_competition_unseen_data_no_labels,index=competition_unseen_data_no_labels_features.index,columns=competition_unseen_data_no_labels_features.columns) \n",
        "# Predict\n",
        "predictions = my_model.predict(scaled_competition_unseen_data_no_labels_df)\n",
        "\n",
        "# Format for submission\n",
        "submission_data = pd.DataFrame({'Id': competition_unseen_data_no_labels.Id, label_name: predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bwg9YTk966rX"
      },
      "source": [
        "Check submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SwNe45U2TKFm"
      },
      "source": [
        "# Submitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5e6007a4-0dac-4a2b-ff8c-ce49a828e3e9",
        "id": "XMojCpBEotX_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "submission_data.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>137989.671756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>162356.539548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>184915.099670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>190389.290452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>202977.424674</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Id      SalePrice\n",
              "0  1461  137989.671756\n",
              "1  1462  162356.539548\n",
              "2  1463  184915.099670\n",
              "3  1464  190389.290452\n",
              "4  1465  202977.424674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMYyBeACDgC9"
      },
      "source": [
        "Verify submission format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LJYIRZvvDgC9",
        "colab": {}
      },
      "source": [
        "tc.assertCountEqual(submission_data.columns, output_sample.columns)\n",
        "assert_series_equal(submission_data.loc[:,'Id'], output_sample.loc[:,'Id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jU5OdaQbDgC_"
      },
      "source": [
        "Write submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YMMRnFDnDgC_",
        "colab": {}
      },
      "source": [
        "submission_data.to_csv(submission_file_location, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LUfP-7adDgDB"
      },
      "source": [
        "Verify submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "267820f1-a7ff-4cfd-b36b-ddb08e173abd",
        "id": "Q04yLgj6DgDB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!head $submission_file_location"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Id,SalePrice\n",
            "1461,137989.67175620998\n",
            "1462,162356.53954769654\n",
            "1463,184915.0996701297\n",
            "1464,190389.29045248844\n",
            "1465,202977.42467415202\n",
            "1466,189724.57229605553\n",
            "1467,176532.14428329555\n",
            "1468,169915.53486787734\n",
            "1469,187041.65284267635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6oDu-XzVDgDD"
      },
      "source": [
        "Submit submitt submitus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e8165fd6-ae8b-4258-8019-4c32cd056298",
        "id": "SMJKvjWzDgDD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!kaggle competitions submit -c house-prices-advanced-regression-techniques -f $submission_file_location -m \"LGBMRegressor 1\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 33.6k/33.6k [00:02<00:00, 13.4kB/s]\n",
            "Successfully submitted to House Prices: Advanced Regression Techniques"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}